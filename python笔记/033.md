## 内容

1. 线程：爬虫使用需要配合前端
2. 协程：异步的框架，异步的爬虫模块
3. 进程：复杂的数据分析或者是提高计算的程序
4. 进程和线程的很多模型、概念基本一致

代码的迭代和重构

线程：

- 线程是进程的一部分，每个进程中至少有一个线程
- 能被cpu调度的最小单位
- 一个进程中的多个线程可以共享这个进程的数据——  数据共享
- 线程的创建、销毁、切换、开销远远小于进程—— 开销小

multiprocessing 模块 Process类

1. 创建一个进程对象
   - 对象和进程的关系：进程对象和进程并没有直接的关系，只是存储了和进程相关的内容，此时OS还没有接到创建进程的指令
2. 开启一个进程
   - start方法的非阻塞和异步的特点
   - 通过，p.start()就开启了一个进程。相当于给了OS一条指令（只有OS 可创建进程）
   - 不等待进程的开启，也不等待OS给的响应
   - 只负责通知OS去开启一个进程
   - 开启了一个子进程后，主进程的代码和子进程的代码完全异步
3. 父进程和子进程之间的关系
   - 父进程会等待子进程结束之后才结束
   - 为了回收子进程资源
4. 进程开启的方式
   - win：通过（模块导入）执行父进程文件中的代码获取父进程中的变量
     - 只要是不希望被子进程执行的代码，就写在if _\_name__ == '\_\_mian\_\_'下
     - 进入导入时，父进程文件中的_\_name__ != '\_\_mian\_\_'
   - linux/macos：通过copy父进程的内存
     - 正常写就可以
   - 公司开发环境都是linux，无需考虑win中的缺陷
5. 如何确认一个主进程执行完毕
   - join方法：主进程阻塞，直到子进程执行完毕
   - 所有的进程执行的先后是由OS控制的
   - 如果开启了多个子进程，等待所有子进程结束

## 今日内容

1. Process类
   - 守护进程
   - 面向对象的方式开启进程
2. 锁的概念(安全问题)
3. 进程间的通信

### 1. Process类

#### 1.1 守护进程

- 生产者消费者模型
- 和守护线程做对比

```python
import time
from multiprocessing import Process

def son1():
  	while True:
        print('is alive')
        time.sleep(0.5)
    
def son2():
  	for i in range(5):
      print('in son2')
      time.sleep(1)
              
if __name__ == '__main__':
    p = Process(target=son1)
    p.daemon = True             # 把p子进程设置成了守护进程
    p.start()
    p2 = Process(target=son2)
    p2.start()
    time.sleep(2)
# 守护进程是随着主进程‘代码’结束而结束
# 所有子进程都必须在主进程结束之前结束
# 守护进程内无法再开启子进程,否则抛出异常：AssertionError: daemonic processes are not allowed to have children
```

#### 1.2 Process的对象的方法

- **异步非阻塞**
  - 使用terminate方法后，再查看进程是否还存活时，会发现进程还存活，并没有等待OS关闭进程，说明terminate方法请求后，程序会继续执行

```python
import time
from multiprocessing import Process

def son1():
  	while True:
        print('is alive')
        time.sleep(0.5)
              
if __name__ == '__main__':
    p = Process(target=son1)
    p.start()                   # 开启了一个进程
  	print(p.is_alive)           # 判断子进程时候存活, Ture和False
    time.sleep(1)
    p.terminate()               # “异步非阻塞”，强制结束一个子进程
    print(p.is_alive)           # True，os还没来得及关闭进程
   	time.sleep(0.01)
    print(p.is_alive)           # False，OS已经响应了关闭进程的需求，再去检测的时候，结果是进程已经结束
```

#### 1.3 面向对象的方式开启进程

- 当创建子进程需要传参时，需要使用super()._\_init__()

```python 
import os
import time
from multiprocessing import Process

class MyProcess(Process):
    def __init__(self, x, y):   # 子进程如果不需要参数，可以省略
        self.x = x
        self.y = y
        super().__init__()        
        
    def run(self):
        while True:
            print(self.x, self.y, os.getpid())
            print('in myprocess')

if __name__ == '__main__':
    mp = MyProcess(1, 2)
    mp.daemon = True
    mp.start()                  # 开启一个子进程，会调用run()方法
    time.sleep(1)
    mp.terminate()							# 结束进程，异步非阻塞						
    print(mp.is_alive())				# True
    time.sleep(0.01)				
    print(mp.is_alive())				# False
```

- p.join() : 同步阻塞
- p.terminate() 和 p.start()：异步非阻
- p.is_alive()：获取当前进程状态
- daemon = True：设置为守护进程，守护进程在主进程代码执行结束而结束

### 2. 锁

1. 在并发的场景下，设计某部分的内容

   - 需要修改一些所有进程共享数据资源

   - 需要加锁来维护数据的安全

2. 在数据安全的基础上，才考虑效率问题

   - with lock：内部会有异常处理
   - 在主进程中进行实例化
   - 把锁传递给子进程

3. 在子进程中对需要加锁的代码进行with lock

   - with lock相当于lock.acquire()和lock.release()

4. 需要加锁的场景

   - 操作共享的数据资源
   - 对资源进行修改操作
   - 加锁之后能够保证数据的安全性，但会降低程序执行效率

```python 
import json
from multiprocessing import Process, Lock             # 导入Lock

def search_ticket(user):
    with open('tickets.txt') as f:
        dic = json.load(f)
        print('%s查询结果：%s张余票' %(user, dic['count']))

def buy_ticket(user, lock):
    search_ticket(user)
    # with lock:
    lock.acquire()
    # time.sleep(0.01)
    with open('tickets.txt') as f:
        dic = json.load(f)
    if dic["count"] > 0:
        print('%s已买到票' % user)
        dic["count"] -= 1
    else:
        print('%s没买到票' % user)
    with open('tickets.txt', 'w') as f:
        json.dump(dic, f)
    lock.release()


if __name__ == '__main__':
    lock = Lock()                                      # 实例化一个对象
    for i in range(10):
        p = Process(target=buy_ticket, args=('user%s '%(i+1), lock))
        p.start()
```

### 3. 进程间的通信

#### 3.1 进程间数据隔离

```python
from multiprocessing import Process
n = 100
def func():
	global n
  n -= 1
 
li = []
for i in range(10):
  p = Process(target=func)
  p.start()
  li.append(p)
  
 for p in li:p.join()
 print(n)
```

#### 3.2 进程间通信

- 文件或网络只有这两种
- 进程间通信(**IPC**， inter  process communication):Queue和Pipe
- **Queue(3)**：先进先出，文件家族的**socket**，写文件基于**pickle**，基于**Lock**
  - 数据安全，**Pipe**管道：天生数据不安全（socket通信）
  - Queue = **Pipe**(socket + picket)**+Lock**

```python
from multiprocessing import Process,Queue

def func(exp,q):
    res = eval(exp)
    q.put(res)

if __name__ == '__main__':
    q = Queue()
    p = Process(target=func, args=('1+2+3',q))
    p.start()
    print(q.get())
```

```python
from multiprocessing import Pipe
pip = Pipe()
pip.send()
pip.recv()
```

```python
# Process中的队列
import Queue
from multiprocessing import Queue
q = Queue(3)													# 可设置队列长度
q.put(1)
q.put(2)															# 对列为满时，继续放数据会发生阻塞
q.put(3)
print('----------')
try:
	q.put_nowait(4)                     # 对列为满时，继续放数据会报错和丢失
except queue.Full:pass
print('----------')

q.get()
q.get()
q.get()                                # 对列为空时，会发生阻塞
try:
	q.get_nowait()											 # 对列为空时，会报错，阻塞会取消
except queue.Empty:pass
```

```python
q.empty()                              # 有缺陷
q.qsize()
q.full()
```

