## 回顾

1. **cp模型**
   - 把一个产生数据并且处理数据的过程分开
   - 让生产数据的过程和处理数据的过程，达到工作效率上的平衡
   - 中间的容器：在多进程我们使用Queue或JoinableQueue，控制数据量
     - 当数据过剩时，队列大小会控制生产者行为
     - 当数据严重不足时，队列会控制消费者行为
     - 通过定期检查队列中的元素个数来调节生产者消费者模型的个数
   - 例如：web程序server端（**6w/s** 请求）
     - 一个服务2000条/s
     - 先写一个web程序，只负责一件事，就是接收请求，然后把请求放到**队列（消息中间件，celery）**中
     - 再写很多个server 端，从对列中获取请求，然后处理，返回结果
2. GIL锁
   - 全局解释器锁(源于gc机制)
   - cpython解释器中的机制(pypy)
   - 导致了在统一进程中多个线程不能同时利用多核—python的多线程只能是并发不能并行
3. threading模块
   1. 创建线程：面向函数、面向对象
   2. 线程中的方法：
      - 属于线程对象：t.star(), t.join()
      - 守护线程：t.daemon = True, 等待所有的非守护子线程都结束之后才结束
        -  非守护线程不结束，主线程也不结束
        - 主线程结束，主进程也结束
        - 结束顺序：非守护线程—>主线程结束—>主进程结束—>主进程结束—>守护线程也结束
   3. threading模块中的函数
      - current_thread：在哪个线程调用，就是返回当前线程对象
      - 活着的，包括主线程
        - enumerate：返回当前活着的线程的对象列表
        - active_count：返回当前活着的线程的个数

- 生成器函数
- 生成器
- for循环 + lambda

## 今日内容

1. 互斥锁
   - 使用互斥锁产生的一个死锁现象
2. 递归锁
3. 线程队列
   - 先进先出
   - 后进先出
   - 优先级队列
4. 池 concurrent.futures

## 9.5 锁

### 1. 互斥锁

```python
# 线程数据同样不安全
import dis
a = 0
def func():
  	global a
  	a += 1
dis.dis(func)                   # 返回cpu指令
```

- 即便是线程，有GIL锁， 也会出现**数据不安全**的问题
- **STORE_GLOBAL**：一旦有这种方法，就会有数据安全问题
- **操作是全局变量**
- **操作以下方法**
  - += , -= , *=, /=（在操作线程全局变量时，注意）

```python
# 使用互斥锁解决线程全局变量数据不安全问题
from threading import Thread, Lock
a = 0
def add_f(lock):
    global a
    with lock:
        for i in range(2000000):
            a += 1
def sub_f(lock):
    global a
    with lock:
        for i in range(2000000):
            a -= 1
lock = Lock()
t1 = Thread(target=add_f, args=(lock,))
t1.start()
t2 = Thread(target=sub_f, args=(lock,))
t2.start()
t1.join()
t2.join()
print(a)
```

**互斥锁**：是锁中的一种：在同一线程中，不能连续lock.acquire()多次

```python
from threading import Lock
lock = Lock()
lock.acquire()
print('-------------')
lock.acquite()
print('-------------')
```

### 2. 单例模式

```python 
import time
import random
from threading import Thread

class Singleton:
    from threading import Lock  # 复用性考虑
    __instance = None
    lock = Lock()
    
    def __new__(cls, *args, **kwargs):
        with cls.lock:
            if not cls.__instance:
                time.sleep(random.random())  # 切换GIL锁
                cls.__instance = super().__new__(cls)
        return cls.__instance
      
    def __init__(self, name, age):
        self.name = name
        self.age = age

def fun():
    print(Singleton('henry', 18))

li = []
for i in range(10):
    t = Thread(target=fun)
    li.append(t)
    t.start()
for t in li: t.join()
```

### 3. 死锁

#### 3.1 原因(2)

- 有**多把锁**(一把以上)
- 多把锁**交替使用**

```python
from threading import Thread,Lock
noodle_lock = Lock()
fork_lock = Lock()
def eat1(name,noddle_lock, fork_lock):
    noddle_lock.acquire()
    print('%s抢到面了'%name)
    fork_lock.acquire()
    print('%s抢到叉子了'%name)
    print('%s吃了一口面'%name)
    noddle_lock.release()
    print('%s放下面了'%name)
    fork_lock.release()
    print('%s放下叉子了'%name)
 
def eat2(name,noddle_lock, fork_lock):
    fork_lock.acquire()
    print('%s抢到叉子了'%name)
    noddle_lock.acquire()
    print('%s抢到面了'%name)
    print('%s吃了一口面'%name)
    noddle_lock.release()
    print('%s放下面了'%name)
    fork_lock.release()
    print('%s放下叉子了'%name)

```

#### 3.2 解决方案

1. **递归锁**
   - 递归锁在同一线程中，可以连续**acquire多次**不会阻塞
   - 本质：一把锁
   - acquire和release次数要一致
   - 优点：在同一线程中多次acquire也不会发生阻塞
   - 缺点：**占用**了更多的**资源**
2. **多把递归锁**也会产生**死锁**现象
   - 使用递归锁，永远不要使用多把
   - 互斥锁效率更高，递归锁效率较低

```python
import time
from threading import RLock, Thread
noodle_lock = fork_lock = RLock()          # 将多把互斥锁变成了一把递归锁

def eat1(name, noodle_lock, fork_lock):
    noodle_lock.acquire()
    print('%s抢到面了' % name)
    fork_lock.acquire()
    print('%s抢到叉子了' % name)
    print('%s吃了一口面' % name)
    time.sleep(0.1)
    fork_lock.release()
    print('%s放下叉子了' % name)
    noodle_lock.release()
    print('%s放下面了' % name)

def eat2(name, noodle_lock, fork_lock):
    fork_lock.acquire()
    print('%s抢到叉子了' % name)
    noodle_lock.acquire()
    print('%s抢到面了' % name)
    print('%s吃了一口面' % name)
    time.sleep(0.1)
    noodle_lock.release()
    print('%s放下面了' % name)
    fork_lock.release()
    print('%s放下叉子了' % name)

lst = ['henry', 'echo', 'dean', 'daniel']
Thread(target=eat1, args=(lst[0], noodle_lock, fork_lock)).start()
Thread(target=eat2, args=(lst[1], noodle_lock, fork_lock)).start()
Thread(target=eat1, args=(lst[2], noodle_lock, fork_lock)).start()
Thread(target=eat2, args=(lst[3], noodle_lock, fork_lock)).start()
```

3. **代码优化**

```python
# 使用互斥锁解决问题
import time
from threading import Lock, Thread

lock = Lock()
def eat1(name, lock):
    lock.acquire()
    print('%s抢到面了' % name)
    print('%s抢到叉子了' % name)
    print('%s吃了一口面' % name)
    time.sleep(0.1)
    print('%s放下叉子了' % name)
    print('%s放下面了' % name)
    lock.release()

def eat2(name, lock):
    lock.acquire()
    print('%s抢到叉子了' % name)
    print('%s抢到面了' % name)
    print('%s吃了一口面' % name)
    time.sleep(0.1)
    print('%s放下面了' % name)
    print('%s放下叉子了' % name)
    lock.release()

lst = ['henry', 'echo', 'dean', 'daniel]
Thread(target=eat1, args=(lst[0], lock)).start()
Thread(target=eat2, args=(lst[1], lock)).start()
Thread(target=eat1, args=(lst[2], lock)).start()
Thread(target=eat2, args=(lst[3], lock)).start()
```

### 4. 队列

- 线程之间的通信，线程安全

```python
import queue
# 先进先出队列：服务
from queue import Queue           
q = Queue(5)
q.put(1)
q.get()
# 后进先出队列：算法
from queue import LifoQueue
lfq = LifiQueue(4)
lfq.put(1)
lfq.put(2)
lfq.get()
lfq.get()
# 优先级队列：自动排序、vip用户、告警级别
from queue import PriorityQueue
pq = PriorityQueue()
pq.put((10, 'henry'))
pq.put((6, 'echo'))
pq.put((10, 'dean'))
pq.get()
pq.get()
pq.get()
```

- FIFO：所有的请求放在对列里，先来先服务思想
- LIFO：一般用于算法

### 5. 进程池/线程池

- 进程，线程开启关闭切换需要时间
- 进程池一般和cpu核心说有关，个数一般为cpu核心数或加一
- 节省了进程创建和销毁的时间

#### 5.1 池

- 预先开启固定个数的进程数，当任务来临时，直接提交给开好的进程，让这个进行执行，从而减轻了os调度的负担

#### 5.2 concurrent futures模块

- 3.4版本之后出现
- **进程池**

```python
# 进程池。 p.submit， p.shutdown
import os,time, random
from concurrent futrures import ProcessPoolExecutor

def func(i):
    print('start', os.getpid())
    time.sleep(random.randint(1,3))
    print('end', os.getpid())
    return '%s * %s' %(i, os.getpid())

if __name__ == '__main__':
    p = ProcessPoolExecutor(5)       # cpu核心数或多一
    ret_l = []
    for i in range(10):
        ret = p.submit(func, i)			 # 提交进程,参数直接放在其后
        ret_l.append(ret)						 # ret为future对象，ret.result()取值
    # 关闭池，不能提交任务，阻塞，直到已经提交的任务执行完毕
    p.shutdown()
    for ret in ret_l:                # 会阻塞，相当于q.get()
      	print('------>',ret.result())# result，同步阻塞
    print('main', os.getpid())
```

- 一个进程池中的任务个数，限制了我们程序的并发个数
- **线程池**

```python
# 线程池。p.submit(), p.shutdown(), ret.result()
from concurrent.futures import ThreadPoolExecutor

def func(i):
    print('start', os.getpid())
    time.sleep(random.randint(1,3))
    print('end', os.getpid())
    return '%s * %s' %(i, os.getpid())

tp = ThreadPoolExecutor(20)            # 线程个数一般为cpu核心数4-5倍
ret_l = []
for i in range(100):
		ret = tp.submit(func, 1)
    ret_l.append(ret)
for ret in ret_l:
  	print('------->', ret.result())
p.shutdown()
print('main')
```

```python
# 线程池。p.submit(), p.shutdown(), ret.result()
from concurrent.futures import ThreadPoolExecutor

def func(i):
    print('start', os.getpid())
    time.sleep(random.randint(1,3))
    print('end', os.getpid())
    return '%s * %s' %(i, os.getpid())

tp = ThreadPoolExecutor(20)            # 线程个数一般为cpu核心数4-5倍
ret = tp.map(func, range(20))					 # tp.map()方法 
for i in ret:print(i)
```

#### 5.3 回调函数

```python
from concurrent.futures import ThreadPoolExecutor
def get_page(url):
  	content = requests.get(url)
    return {'url':url, 'content':content.text}
def parserpage(dic):
  	print(dic.result()['url'])

for url in url_l:
  	ret = get_page(url)
    ret.add_done_callback(parserpage)   # 先执行完，先调用parserpage函数
    																		# ret=add_done_callback(函数名)
```

