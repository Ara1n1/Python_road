1.  friend_list
2.  chat_list
3.  app_uploader
4.  toy_uploader
5.  text2audio
6.  audio2text
7.  nlp
    1.  问题：将直接播放消息，改为间接手动播放消息
    2.  语音合成消息提醒，思考：你有未读消息--> 你有来自xx的消息 --> xx是用户的昵称吗
    3.  文件名称，最终返回值

## redis存储未读消息

```python
# redis放置在内网中
{
    k:"{}"
}
k:当前收消息方
{}: 
{
    'send1':1,   # 读取一次，清空即 0 
    'send2':2,
}
```

```python
from redis import Redis
RDB = Redis(host='127.0.0.1', port=6379)
# 设置未读消息
def set_msg(sender, receiver):
    1. 当前没有receiver的数据，创建receiver字典
    msg_count = RDB.get(receiver)
    if msg_count:
        2. 当receiver收到 sender 消息，对应 sender + 1
        msg_dit = json.loads(msg_count)
        if msg_dit.get(sender):
           	msg_dit[sender] += 1
#        else:
#            msg_dit[sender] = 1
#        msg_count = json.dumps(msg_dit)
#     else:
#        msg_count = json.dumps({sender:1}) 
     msg_count = msg_dit.setdefault(sender,1)
     RDB.set(receiver, json.dumps(msg_count)) 

# 获取未读消息
def get_msg(sender, receiver):
    msg_count = RDB.get(receiver)
    if msg_count:
        msg_dict = json.loads(msg_count)
        count = msg_dict.get(sender, 0)
        msg_dict[sender] = 0
    else:
        count = 0
        msg_dict = {sender:0}
    RDB.set(receiver, json.dumps(msg_dict))
    return count
```

```python
# 点播歌曲
def my_nlp_lowB(Q, toy_id):
    # 理解 Q 的意图
    # 1. 点播歌曲
    # 2. 主动发起聊天
    
    # 3.
```

1.  好友关系
2.  单方关系
3.  陌生人关系

## 添加好友

1.  名片获取，发送方
2.  发送好友请求，好友请求信息
3.  接收方，同意、拒绝、忽略

-   add_req
-   req_list
-   ref_req
-   acc_req

## 本地文本相似度处理

### 1. nlp处理分词

-   中文分词 -- 世界级问题
-   pypinyin模块：**汉字转拼音**

```python
# pip install pypinyin
from pypinyin import lazy_pinyin, TONE,TONE2,TONE3
s = '我想听小毛驴'
res1 = lazy_pinyin(s, style=TONE)
res2 = lazy_pinyin(s, style=TONE2)
res3 = lazy_pinyin(s, style=TONE3)
print(res1, res2, res3)
s = ''.join(res3)
```

-   jieba模块：**中文分词**

```python
# pip install jieba
import jieba
s = '我想听小毛驴'
# res是生成器
res = jieba.cut(s)
res2 = list(jieba.cut_for_search(a))
# 追加自定义分词
jieba.add_word('我想听')
```

-   gensim模块

```python
# 机器学习综合库-- NLP语言模型 相似度算法
from gensim import corpora, models, similarities



# 制作语料库
dictionary = corpora.Dirtionary()  # 词袋，把每个词对应编号存到dict中
dictionary.doc2bow(doc)  # [(1, 1),(4,1)...]

# 语言模型，使用 corpus：语料库
lsi = models.LsiModel(corpus)    # 数据量小相对精确(500万以内)
lsi[corpus]						# 获取语料库的模型
TfidfModel # 大数据量


# 先分词--词袋(类似setdefault，词:num)[(1,2),(4,1)]--模型--稀疏矩阵相似度算法





def my_nlp(Q:str):
    
```

## 玩具功能

1.  主动发消息
2.  **玩具间对话**
3.  智能指令
4.  接收app推送的歌曲

## APP

1.  展示幼教内容
2.  添加、绑定玩具
3.  控制玩具的好友

```python
1. FLASK
2. WEBSOCKET
3. MONGODB
4. AI
5. UPLOADER
```

FLASK服务：业务逻辑

WEBSOEKT：通信服务

文件server：数据

逻辑通信服务器(热备份)







