

## 1. 单线程+多任务异步协程

```python
from multiprocessing.dummy import Pool
import requests, time

pool = Pool(20)
urls = [url1, url2...]
def fun(url):
    return requests.get(url)

if __name__ == '__main__':
    start = time.time()    
   	res = pool.map(fun, urls)
    print(time.time()-start)
	print(res)
# 返回值可以继续使用 map 方法进行数据解析
```

-   单线程开启500个左右协程，异步效果较佳
-   **协程**：在Pyhton中，协程是一个对象，当作是一个特殊的函(函数的定义被asynic关键字所修饰)，被调用后函数内部的程序语句**不会被立即执行**而是会返回一个协程对象。
-   await：挂起的操作，交出cpu的使用权，需要手动操作，结束会继续执行

```python
import asyncio
from time import sleep
async def get_req(url):
    print(f'正在请求{url}')
    # 阻塞操作
    await asynico.sleep(2)
    print(f'请求{url}结束')
    return 'hello'

res = get_req('http://www.1.com')
print(res)
```

-   任务对象(task)：就是对协程对象的进一步封装，在任务对象中可以**实现显示协程对象的运行状况**。
-   任务对象最终是需要被**注册到事件循环对象中**
    -   **绑定回调**：回调对象是绑定给任务对象，只有当任务对象执行完成后，执行
-   事件循环对象：**无限循环的对象**，也可以把其当成是某一种容器，该容器中需要放置多个任务对象
-   当事件循环开启后，该对象会按照顺序执行每一个任务对象，当一个任务对象发生了阻塞，事件循环不会等待，而是直接执行下一个任务对象

```python
# 接上个代码块
# 默认参数 task 是任务对象
def callback(task):
    print('callback')
    print(task.result())

# 创建一个协程对象
c = get_req('url')
# 封装一个任务对象(一组待执行的代码块)
task = asyncio.ensure_future(c)
# 给任务对象绑定回调函数
task.add_done_callback(callback)
# 创建一个事件循环对象，并注册任务对像，开启事件循环
loop = async.get_event_loop()
loop.run_until_compeleted(task)
```

-   多任务协程
    -   将多个任务对象存储到一个list中，然后将list注册到事件循环中，在注册过程中，**task_list需要被wait方法处理**
    -   在协程函数内部，不可以出现不支持异步模块的代码，否则会中断整个异步效果，并且在函数内部每一组阻塞操作必须使用await关键字修饰

```python
urls = [url1, url2...]

task_li = []
for url in urls:
    c = get_req(url)
    task = asyncio.ensure_future(c)
    task_li.append(task)
    
# asyncio.wait(task_li)，task中必须使用await
loop = asyncio.get_event_loop()
loop.run_until_compeleted(asyncio.wait(task_li))
```

-   requests不支持异步的模块：无法实现异步效果
-   aiohttp的使用：支持异步操作的网络请求模块
-   每个with操作都需要加入 **async**，以及阻塞操作前加 **await**
    -   获取响应内容，.text() / read() 也是阻塞操作

```python
# 安装
pip install aiohttp
# 导入
import aiohttp

async def req(url):
    async with aiohttp.ClientSession() as s:
        async with await s.get(url, headers=headers, proxy='http://ip+port') as response:
            # response.read() 返回bytes类型
            page_text = await response.text()
            return page_text
def parse(task):
    page_text = task.result()
    pass
    
task_li = []   
for i in urls:
    c = req(url)
    task = asynico.ensure_future(c)
    task.add_done_callback(parse)
    task_li.append(task)

loop = asyncio.get_event_loop()
loop.run_until_complete(asyncio.wait(task_li))
```

## 2. selenium

-   12306 模拟登录

### 1. 概念

-   基于浏览器自动化的一个模块
-   selenuim：
    -   pip install selenium
    -   便捷的获取页面动态加载的数据，实现模拟登录

### 2. 基本操作

-   chrome驱动程序下载地址 ： `http://chromedriver.storage.googleapis.com/index.html`

1.  实例化浏览器对象
2.  find系列函数用于标签定位

```python
from selenium import webdriver

# 实例化一个浏览器对象(驱动程序路径)
bro = webdriver.Chrome(executable_path='对应的驱动程序')
url = 'https://www.jd.com/'b
bro.get(url)					# 用于发起请求
# 定位标签(find系列) --> 对标签数据交互
search_input = bro.find_element_by_id('key')
search_input.send_keys('macPro')
btn = bro.find_element_by_xpath('xxxx')
btn.click()
# 执行 js 代码
jsCode = 'window.scrollTo(0, document.body.scrollHeight)'
bro.excute_script(jsCode)
bro.quit()
```

-   selenium
    -   requests模块进行数据爬取，可见非可得
    -   selenium：可见即可得
    -   速度较慢

```python
# 爬取动态数据
# page_source 就是浏览器打开对应的源码数据
from lxml import etree
page_text = bro.page_source
tree = etree.HTML(page_text)
tag = tree.xpath('xxx')
print(tag)
```

### 3. 动作链

-   iframe：页面中的子页面
-   如果定位的标签是存在于 iframe 子页面中，在标签定位前一定要执行一个**switch_to** 操作，切换作用域

```python
from selenium import webdriver
from selenium.webdriver import ActionChains
bro = webdriver.Chrome(executable_path='对应的驱动程序')
url = 'xxx'
bro.get(url)
bro.switch_to.frame('iframeResult')
div_tag = bro.find_element_by_id('id')

# 使用动态链
1. 实例化对象
action = ActionChains(bro)
2. 点击长按
action.click_and_hold(div_tag)
3. 滑动
for i in range(5):
    # perform(), 表示让动作链立即执行
    action.move_by_offset(17, 0).perform()
    sleep(0.5)
action.release()

sleep(3)
bro.quit()
```

#### selenium操作小结

```python
# 基本操作
bro = webdriver.Chrome(executable_path='对应的驱动程序')
bro.get(url)
bro.find_element_by_id('id')
input_tag.send_keys('value')
btn.click()
bro.excute_script('js代码')
bro.quit()
bro.swith_to.frame('frame名称')
bro.save_screenshot('保存路径')
# 动态链，action的事件必须添加 perform(),否则不会触发
action = ActionChains(bro)
action.click_and_hold(div_tag)
action.move_by_offset(17, 0).perform()
action.release()
```

### 4. 无头浏览器

-   无可视化界面的浏览器
-   phantomJS：**无可视化界面的浏览器**，已停止更新

```python
ph = webdriver.PhatomJS(executable_path='xxx')
```

-   使用chrome

```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from time import sleep
# 创建一个参数对象，用来控制chrome以无界面模式打开
chrome_options = Options()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--disable-gpu')
#实例化一个浏览器对象
bro = webdriver.Chrome(executable_path='对应的驱动程序',chrome_options=chrome_options)
bro.get('https://www.baidu.com')
sleep(2)
bro.save_screenshot('test.png')
print(bro.page_source)
sleep(2)
bro.quit()
```

### 5. selenium反爬

```python
# console,返回 undifinded 则是正常用户发起，true表示是由selenium发起
window.navigator.webdriver
```

-   规避被检测 selenium 的风险

```python
from time import sleep
from selenium import webdriver
from selenium.webdriver import ChromeOptions
option = ChromeOptions()
option.add_experimental_option('excludeSwitches', ['enable-automation'])
#实例化一个浏览器对象
bro = webdriver.Chrome(executable_path=executable_path='对应的驱动程序',options=option)
```

## 3. selenium应用

-   模拟登录12306
-   pillow模块中的 Image，用于图片裁剪

```python
import selenium import webdriver
from selenium.webdriver import ActionChains
from PIL import Image

# 实例化
bro = webdriver.Chrome(executable_path='chromedriver')
action = ActionChains(bro)

bro.get('https://kyfw.12306.cn/otn/resources/login.html')
# 截取验证码图片并进行裁剪
bro.save_screenshot('main.png')
image_tag = bro.find_element_by_xpath('xxxx')
# location返回左上角的坐标，size表示尺寸(长、宽)
loc = image_tag.location
size = image_tag.size
rect = (int(loc['x']), int(loc['y']), int(loc['x'])+int(size['width']),  int(loc['y'])+int(size['height']))
# 进行裁剪
i = Image.open('main.png')
frame = i.crop(rect)
frame.save('code.png')
# 调用超级鹰，获取验证码结果
xy =   --> [[x1,y1],[x2,y3],[x3,y3]...]  # 坐标(0,0)是验证码图片的左下角
# action需要单独序列化
for ax in xy.split('|'):
    x,y = int(ax[0]), int(ax[1])
    ActionChains(bro).move_to_elemnt_with_offset(image_tag, x, y).click().perform()
    sleep(0.5)

sleep(3)
bro.quit()
```

## 3. 空气质量数据爬取

-   ajax请求数据
-   提前加载好的数据

1.  综合板块对应的数据：将当前页面的搜索条件进行修改后，点击搜索按钮，才可以通过抓包工具补货到ajax请求的数据包
2.  响应数据是加密数据的密文数据，请求参数是动态变化的
    -   含义不清晰的请求参数一般都是动态变化的
3.  找到搜索按钮点击所对应的点击事件(通过firefox操作)，发现搜索按钮的click事件：getData()，在该函数内部有一个type=='HOUR'，
    -   getAQIData() 和 getWeatherData()中定义了method和param两个变量，并且method值为'GETDETAIL',param={city, type,start,end}四个健值对，还有另一个函数的调用getServerData(method, param, 回调函数，0.5)的调用
    -   找到getServerData()函数的定义(jquery文件中)，发现是经过加密(**js混淆**)的js函数实现
    -   将混淆的数据进行js反混淆：第三方网站
    -   经过反混淆后，获取了getServerData()定义并进行分析
        -   找到了ajax请求的相关参数
        -   找到了动态请求参数的来源：getParam(method, object)
        -   ajax请求到的密文数据进行解密的js函数：decodeData(data)，该函数返回值就是解密后的数据
        -   问题：函数定义都是js语言的，如果使用python语言，需要借助 pyexecjs 模块
4.  pyexecjs的使用
    -   在python中使用pyexecjs模块，必须事先安装好node.js环境












