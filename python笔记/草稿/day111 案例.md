## 美国12政治选举案例

-   需求

```python
#字段说明
cand_nm(候选人姓名),contbr_nm（捐赠者姓名）, contbr_city,contbr_st, contbr_zip, contbr_employer, contbr_occupation（捐赠者的职业）, contb_receipt_amt（捐赠金额）, contb_receipt_dt（捐赠日期）
# 具体需求
1. 读取文件usa_election.txt
2. 查看文件样式及基本信息
3.【知识点】使用map函数+字典，新建一列各个候选人所在党派party
4. 使用np.unique()函数查看colums：party这一列中有哪些元素
5. 使用value_counts()函数，统计party列中各个元素出现次数，value_counts()是Series中的，无参，返回一个带有每个元素出现次数的Series
6.【知识点】使用groupby()函数，查看各个党派收到的政治献金总数contb_receipt_amt
7. 查看具体每天各个党派收到的政治献金总数contb_receipt_amt 。使用groupby([多个分组参数])
8. 将表中日期格式转换为'yyyy-mm-dd'。日期格式,通过函数加map方式进行转换
9. 得到每天各政党所收政治献金数目。  考察知识点：groupby（多个字段）
10.查看老兵(捐献者职业)DISABLED VETERAN主要支持谁  ：查看老兵们捐赠给谁的钱最多
11.找出各个候选人的捐赠者中，捐赠金额最大的人的职业以及捐献额  .通过query("查询条件来查找捐献人职业")
```

```python
# 统计出现次数
df['party'].value_counts()
# 多次分组，必须注意 by=[]，中的分组顺序。类似文件的树形结构
```

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# 1.读取文件usa_election.txt, 2.查看文件样式及基本信息
usa_election = pd.read_csv('./data/usa_election.txt')
usa_election.head(2)
# 3.【知识点】使用map函数+字典，新建一列各个候选人所在党派party
usa_election['parties'] = usa_election['cand_nm'].map(parties)
usa_election.head(2)
# 4.使用np.unique()函数查看colums：party这一列中有哪些元素
usa_election.parties.unique()
# 5.使用value_counts()函数，统计party列中各个元素出现次数，value_counts()是Series中的，无参，返回一个带有每个元素出现次数的Series
usa_election.parties.value_counts()
# 6.【知识点】使用groupby()函数，查看各个党派收到的政治献金总数contb_receipt_amt
usa_election.groupby(by='parties').contb_receipt_amt.sum()
# 7.查看具体每天各个党派收到的政治献金总数contb_receipt_amt 。使用groupby([多个分组参数])
usa_election.groupby(by=['contb_receipt_dt', 'parties']).sum()
# 8.将表中日期格式转换为'yyyy-mm-dd'。日期格式,通过函数加map方式进行转换
date = usa_election.contb_receipt_dt
def transformDate(data):
    for i in range(len(date)):
        new_date = {}
        day, month, year = date[i].split('-')
        month = months[month]
        return '-'.join(['20'+year, str(month), day])

usa_election['contb_receipt_dt'] = usa_election.contb_receipt_dt.map(transformDate)
usa_election.head(2)
# 9.得到每天各政党所收政治献金数目。 考察知识点：groupby（多个字段）
usa_election.groupby(by=['contb_receipt_dt', 'parties']).contb_receipt_amt.sum()
# 10.查看老兵(捐献者职业)DISABLED VETERAN主要支持谁 ：查看老兵们捐赠给谁的钱最多
df = usa_election[usa_election.contbr_occupation =='DISABLED VETERAN']
df.groupby(by='cand_nm').contb_receipt_amt.sum()
# 11.找出各个候选人的捐赠者中，捐赠金额最大的人的职业以及捐献额 .通过query("查询条件来查找捐献人职业")
max_amt = usa_election.groupby(by=['cand_nm'])['contb_receipt_amt'].max()
max_amt

for i in range(max_amt.size):
    max_money = max_amt[i]
    # for 循环中不显示执行结果，需要使用display或者print
    display(usa_election.query('contb_receipt_amt == '+str(max_money))
```

## 城市气候与海洋的关系研究

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pandas import Series,DataFrame
from pylab import mpl
mpl.rcParams['font.sans-serif'] = ['FangSong'] 			# 指定默认字体
mpl.rcParams['axes.unicode_minus'] = False 				# 解决保存图像是负号'-'显示为方块的问题
# 
pd.concat([df1, df2, df3], ignore_index=True)
plt.scatter(li1, li2)
plt.xlabel = 'distance'
plt.ylabel = 'temperature'
plt.title = 'dis-temp'
```

## sklearn模块

-   Anaconda 中集成

### 1. 概念

1.  人工智能和机器学习之间的关系
    -   机器学习是实现人工智能的一种技术手段
2.  算法模型
    1.  概念：特殊对象该对象内部封装了某种还没有求出解的方程
    2.  作用：实现预测或分类
    3.  对象内部封装的方程的解就是算法模型预测或分类的结果
    4.  分类
        -   有监督学习：如果算法模型对象需要的样本数据必须有特征数据和目标数据
        -   无监督学习：只需要特征数据即可
3.  样本数据
    1.  训练模型：样本数据和算法模型之间的关系(需要将样本数据带入到模型对象中，让模型对象的方程求出解)
    2.  算法模型的样本数据：千亿级别的样本数据
    3.  样本数据：由特征数据(自变量，往往是由多种特征组成)和目标数据(因变量)组成

### 2. 线性回归算法模型(预测)

```python
# 建立一个温度模型，让其可以根据距离，预测出该距离对应城市的最高温度
# 导入sklearn，建立线性回归模型
from sklearn.linear_model import LinearRegression
# 实例化算法模型对象, y = kx + b
linear = LinearRegression()

# 样本数据提取，一般封装到 np的 array 中
feature = np.array(distance)
target = np.array(max_temp)
# 训练模型，特征数据必须是二维的
linear.fit(feature.reshape(-1,1), target)
# 基于训练好的模型对象实现预测功能(获取方程解)
linear.predict([[266],[333]])

x = np.linspace(0, 400, num=100)
y = linear.predict(x.reshape[-1,-1])
plt.scatter(distance, max_temp)
plt.scatter(x, y)
```

### 3. KNN(分类算法模型)

#### 1. k-近邻算法原理

-   俗称：k近邻、K：数值，N：nearest，N：neighbor
-   欧几里德距离：Euclidean Distance
-   简单地说，K-近邻算法采用测量不同特征值之间的距离方法进行分类。
    1.  优点：精度高、对异常值不敏感、无数据输入假定。
    2.  缺点：时间复杂度高、空间复杂度高。
    3.  适用数据范围：数值型和标称型。

#### 2. 工作原理

-   存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据 与所属分类的对应关系。输人没有标签的新数据后，将新数据的每个特征与样本集中数据对应的 特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们 只选择样本数据集中前K个最相似的数据，这就是K-近邻算法中K的出处,通常*K是不大于20的整数。 最后 ，选择K个最相似数据中出现次数最多的分类，作为新数据的分类*。
-   回到前面电影分类的例子，使用K-近邻算法分类爱情片和动作片。有人曾经统计过很多电影的打斗镜头和接吻镜头，下图显示了6部电影的打斗和接吻次数。假如有一部未看过的电影，如何确定它是爱情片还是动作片呢？我们可以使用K-近邻算法来解决这个问题。

#### 3. 在scikit-learn库中使用k-近邻算法

- 分类问题：from sklearn.neighbors import KNeighborsClassifier
- 回归问题：from sklearn.neighbors import KNeighborsRegressor

```python
# scikit-learn库库中使用k-近邻算法
df = pd.read_csv('./film.txt')
feature = df[['Action lens'],['Love lens']]
target = df['target']
# 导入模型
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(feature, target)
# knn模型训练打分结果
knn.score(feature, target)
knn.predict([[30], [50]])
```

### 4. 数据

-   提供机器学习的测试数据

```python
# 提供机器学习的测试数据
from sk-learn.datasets as datasets
datasets.load_iris()
```

```python
# 训练数据
x_train = feature[0:32500]
y_train = target[0:32500]
# 测试数据,测试模型的精准度
x_test = feature[32500:]
y_test = target[32500:]
# 实例化模型
knn = KNeighborsClassifier(n_neighbors=30)
knn.fit(x_train, y_train)
knn.score(x_train, y_train)
# 测试模型精准度
print(knn.predict(x_test), y_test)
```

### 5. 手写数据识别

```python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearing.neighbors import KNeighborsClassifier

# 1.提取样本数据
feature = []
target = []
for i in range(10):
    for j in range(1, 501):
        img_path = f'./data/{i}/{i}_{j}.bmp'
        img_arr = plt.imread(img_path)
        feature.append(img_arr)
        target.append(i)

# 2.将list类型样本转为 array 形式
feature = np.array(feature)
target = np.array(target)

# 3.特征数据是三维的，不可作为训练数组，必须转换成二维数组
feature = feature.reshape((5000, 784))
# 只能固定一个随机函数的随机因子
np.random.seed(10)
np.random.shuffle(feature)
np.random.seed(10)
np.random.shuffle(feature)
# 训练数据和测试数据
x_train = feature[:4980]
y_train = target[:4980]
x_test = feature[4980:]
y_test = target[4980:]
# 4.生成训练模型
knn = KNeighborsClassfier(n_negihbors=17)
knn.fit(x_train, y_train)
knn.score(x_train, y_train)

print(knn.predict(x_test))
print(y_test)

# 5.将训练好的模型进行保存
from sklearn.externals import joblib
joblib.dump(knn, './knn.m')
# 加载保存的模型
knn = joblib.load('./knn.m')

# 6.让模型对外部一张图片进行识别(应用)
ex_img = plt.imread('./test.jpg')
# 将多个数字进行裁剪
img_two = ex_img[:70,130:185,:]
# 外部图片数据是三维，实现降维
img_two = img_two.mean(axis=2)
# 像素调整，等比例压缩
import scipy.ndimage as ndimages
img_two = ndimage.zoom(img_two, zoom=(28/75, 28/55))
# 将图片转换为一维数组
img_two = img_two.reshape((1, -1))
knn.predict(img_two)
```













